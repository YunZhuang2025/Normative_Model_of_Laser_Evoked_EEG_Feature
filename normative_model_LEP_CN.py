#!/usr/bin/env python3
"""
åŸºäºPCNtoolkitçš„æ¿€å…‰è¯±å‘è„‘ç”µç‰¹å¾å€¼Normative model
ä½œè€…: Yun Zhuang
æ—¥æœŸ: 2025-11-27
ç‰ˆæœ¬: v1.0
å¦‚æœä½¿ç”¨æœ¬å·¥å…·å‘è¡¨è®ºæ–‡ï¼Œè¯·å¼•ç”¨ï¼š
Zhuang Y., Zhang L.B., Wang X.Q., Geng X.Y., & Hu L., (in preparation) From Normative Features to Multidimensional Estimation of Pain: A Large-Scale Study of Laser-Evoked Brain Responses.
"""

import json
import numpy as np
import pandas as pd
from pathlib import Path
from scipy.interpolate import BSpline
import sys
import argparse
import warnings

warnings.filterwarnings('ignore')


def softplus(x, params=(0.0, 3.0)):
    """
    Softplusæ˜ å°„å‡½æ•°
    sigma = scale * log(1 + exp((x - shift) / scale))
    """
    shift, scale = params
    x_scaled = (x - shift) / scale
    # è£å‰ªé˜²æ­¢æº¢å‡º
    x_clipped = np.clip(x_scaled, -20, 20)
    return scale * np.log1p(np.exp(x_clipped))


def create_bspline_basis(x, knots, degree=3):
    """
    åˆ›å»ºB-splineåŸºå‡½æ•°çŸ©é˜µ
    
    å‚æ•°:
        x: è¾“å…¥å€¼ï¼ˆæ ‡å‡†åŒ–åçš„ï¼‰
        knots: èŠ‚ç‚¹å‘é‡
        degree: B-splineé˜¶æ•°
    
    è¿”å›:
        basis_matrix: shape (n_bases,) æˆ– (n_samples, n_bases)
    """
    x = np.atleast_1d(x)
    knots = np.array(knots)
    n_bases = len(knots) - degree - 1
    
    basis_values = []
    for i in range(n_bases):
        c = np.zeros(n_bases)
        c[i] = 1.0
        bspl = BSpline(knots, c, degree, extrapolate=True)
        basis_values.append(bspl(x))
    
    basis_matrix = np.column_stack(basis_values)
    
    # å¦‚æœè¾“å…¥æ˜¯å•ä¸ªå€¼ï¼Œè¿”å›1Dæ•°ç»„
    if basis_matrix.shape[0] == 1:
        return basis_matrix.flatten()
    
    return basis_matrix


class HBRPredictorByFeature:
    """
    HBRé¢„æµ‹å™¨ - æŒ‰ç‰¹å¾åˆ†åˆ«è®­ç»ƒç‰ˆæœ¬
    
    ç‰¹ç‚¹ï¼š
    - æ¯ä¸ªç‰¹å¾æœ‰ç‹¬ç«‹çš„è®­ç»ƒæ•°æ®å’Œæ ‡å‡†åŒ–å‚æ•°
    - è‡ªåŠ¨å¤„ç†ä¸åŒç‰¹å¾å¯èƒ½æœ‰ä¸åŒçš„inscaler
    - ç»Ÿä¸€çš„åå˜é‡è¾“å…¥æ¥å£
    """
    
    def __init__(self, params_file=None, custom_inscaler=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        å‚æ•°:
            params_file: å‚æ•°æ–‡ä»¶è·¯å¾„
            custom_inscaler: è‡ªå®šä¹‰inscalerå­—å…¸ï¼Œæ ¼å¼ {'mean': [...], 'std': [...]}
                            å¦‚æœæä¾›ï¼Œå°†è¦†ç›–æ‰€æœ‰ç‰¹å¾çš„inscaler
        """
        # è‡ªåŠ¨æŸ¥æ‰¾å‚æ•°æ–‡ä»¶
        if params_file is None:
            params_file = self._find_params_file()
        
        params_path = Path(params_file)
        if not params_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°å‚æ•°æ–‡ä»¶: {params_file}")
        
        # åŠ è½½æ¨¡å‹å‚æ•°
        print(f"æ­£åœ¨åŠ è½½å‚æ•°æ–‡ä»¶: {params_file}")
        with open(params_file, 'r', encoding='utf-8') as f:
            self.model_params = json.load(f)
        
        self.params_file = str(params_path)
        self.custom_inscaler = custom_inscaler
        
        # ç‰¹å¾åç§°ï¼ˆæŒ‰ç…§æœŸæœ›çš„é¡ºåºï¼‰
        feature_order = ['N1_amp', 'N2_amp', 'P2_amp', 
                        'ERP_mag', 'alpha_mag', 'beta_mag', 'gamma_mag']
        self.feature_names = [f for f in feature_order if f in self.model_params]
        
        if not self.feature_names:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ç‰¹å¾æ¨¡å‹ï¼")
        
        # ä¸ºæ¯ä¸ªç‰¹å¾å‡†å¤‡inscaler
        self._prepare_inscalers()
        
        # åå˜é‡èŒƒå›´ï¼ˆåŸºäºè®­ç»ƒæ•°æ®çš„ç»Ÿè®¡ï¼‰
        self.covariate_names = ['laserpower', 'gender', 'age', 'height']
        self.ranges = {
            'laserpower': {'min': 1.0, 'max': 4.5, 'rec_min': 2.5, 'rec_max': 4.0},
            'gender': {'min': 1, 'max': 2},
            'age': {'min': 16.0, 'max': 50.0, 'rec_min': 18.0, 'rec_max': 25.0},
            'height': {'min': 150.0, 'max': 190.0}
        }
    
    def _find_params_file(self):
        """è‡ªåŠ¨æŸ¥æ‰¾å‚æ•°æ–‡ä»¶"""
        candidates = [
            'extracted_model_params.json',
            Path(__file__).parent / 'extracted_model_params.json',
            Path(__file__).parent.parent / 'extracted_model_params.json',
            Path.cwd() / 'extracted_model_params.json',
        ]
        
        for candidate in candidates:
            if Path(candidate).exists():
                return str(candidate)
        
        return 'extracted_model_params.json'
    
    def _prepare_inscalers(self):
        """
        ä¸ºæ¯ä¸ªç‰¹å¾å‡†å¤‡inscaler
        
        ä¼˜å…ˆçº§:
        1. å¦‚æœæä¾›äº†custom_inscalerï¼š
           - å¦‚æœæ˜¯å­—å…¸ï¼ˆæ¯ä¸ªç‰¹å¾ç‹¬ç«‹å€¼ï¼‰ï¼Œä½¿ç”¨ç‰¹å¾ä¸“å±å€¼
           - å¦‚æœæ˜¯å•ä¸€å€¼ï¼ˆå…¨å±€å…±äº«ï¼‰ï¼Œæ‰€æœ‰ç‰¹å¾ä½¿ç”¨ç›¸åŒå€¼
        2. å¦åˆ™ä½¿ç”¨æ¨¡å‹å‚æ•°ä¸­çš„inscalerï¼ˆæ¯ä¸ªç‰¹å¾ç‹¬ç«‹ï¼‰
        3. å¦‚æœéƒ½æ²¡æœ‰ï¼Œä½¿ç”¨å…¨å±€é»˜è®¤å€¼
        
        é‡è¦ï¼šæ¯ä¸ªç‰¹å¾å¯èƒ½æœ‰ä¸åŒçš„inscalerï¼ˆå› ä¸ºå‰”é™¤äº†ä¸åŒçš„å¼‚å¸¸å€¼ï¼‰
        """
        self.inscalers = {}
        
        # å…¨å±€é»˜è®¤inscalerï¼ˆä»…ä½œä¸ºåå¤‡ï¼Œç²¾åº¦å¯èƒ½ä¸å¤Ÿï¼‰
        # å¯¹åº”é¡ºåº: laserpower, gender, age, height
        default_inscaler = {
            'mean': np.array([3.3427, 1.6024, 24.5392, 167.5705]),
            'std': np.array([0.6794, 0.4894, 3.4240, 7.1038])
        }
        
        # æ£€æŸ¥ custom_inscaler çš„ç±»å‹
        if self.custom_inscaler is not None:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å­—å…¸ï¼ˆæ¯ä¸ªç‰¹å¾ç‹¬ç«‹ï¼‰
            if isinstance(self.custom_inscaler, dict):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å¾åä½œä¸ºé”®
                has_feature_keys = any(f in self.custom_inscaler 
                                      for f in self.feature_names)
                
                if has_feature_keys:
                    # æ¯ä¸ªç‰¹å¾ç‹¬ç«‹çš„inscaler
                    print("ä½¿ç”¨ç‰¹å¾ä¸“å±inscaler:")
                    for feature in self.feature_names:
                        if feature in self.custom_inscaler:
                            inscaler = self.custom_inscaler[feature]
                            self.inscalers[feature] = {
                                'mean': np.array(inscaler['mean']),
                                'std': np.array(inscaler['std'])
                            }
                            print(f"  âœ“ {feature}: ä½¿ç”¨è‡ªå®šä¹‰inscaler")
                        else:
                            # è¯¥ç‰¹å¾æ²¡æœ‰æä¾›ï¼Œä½¿ç”¨é»˜è®¤
                            self.inscalers[feature] = default_inscaler
                            print(f"  âš ï¸  {feature}: æœªæä¾›ï¼Œä½¿ç”¨é»˜è®¤inscaler")
                else:
                    # å…¨å±€å…±äº«çš„inscaler
                    print("ä½¿ç”¨å…¨å±€å…±äº«inscaler:")
                    print(f"  mean: {self.custom_inscaler['mean']}")
                    print(f"  std: {self.custom_inscaler['std']}")
                    shared_inscaler = {
                        'mean': np.array(self.custom_inscaler['mean']),
                        'std': np.array(self.custom_inscaler['std'])
                    }
                    for feature in self.feature_names:
                        self.inscalers[feature] = shared_inscaler
            else:
                raise ValueError("custom_inscaler å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        else:
            # ä»æ¨¡å‹å‚æ•°ä¸­è¯»å–ï¼ˆæ¯ä¸ªç‰¹å¾ç‹¬ç«‹ï¼‰
            print("ä»æ¨¡å‹å‚æ•°ä¸­è¯»å–inscaler...")
            
            has_any_inscaler = False
            for feature in self.feature_names:
                params = self.model_params[feature]
                inscaler = params.get('inscaler', {})
                
                # æ£€æŸ¥inscaleræ˜¯å¦æœ‰æ•ˆ
                mean = inscaler.get('mean', [])
                std = inscaler.get('std', [])
                
                if isinstance(mean, list) and len(mean) == 4 and \
                   isinstance(std, list) and len(std) == 4:
                    # ä½¿ç”¨ç‰¹å¾ä¸“å±çš„inscaler
                    self.inscalers[feature] = {
                        'mean': np.array(mean),
                        'std': np.array(std)
                    }
                    print(f"  âœ“ {feature}: ä½¿ç”¨æ¨¡å‹å‚æ•°ä¸­çš„inscaler")
                    has_any_inscaler = True
                else:
                    # ä½¿ç”¨å…¨å±€é»˜è®¤inscaler
                    self.inscalers[feature] = default_inscaler
                    print(f"  âš ï¸  {feature}: æ¨¡å‹å‚æ•°ä¸­æ— inscalerï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            if not has_any_inscaler:
                print("\nâš ï¸  è­¦å‘Š: æ‰€æœ‰ç‰¹å¾éƒ½ç¼ºå°‘inscalerï¼Œä½¿ç”¨é»˜è®¤å€¼")
                print("   å»ºè®®: è¿è¡Œ compute_inscalers_matlab.m è®¡ç®—å‡†ç¡®çš„inscaler")
        
        print()
    
    def check_input(self, laserpower, gender, age, height):
        """
        æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        
        è¿”å›:
            warnings: è­¦å‘Šä¿¡æ¯åˆ—è¡¨
            severity: ä¸¥é‡ç¨‹åº¦ ('none', 'low', 'medium', 'high')
        """
        warnings_list = []
        severity = 'none'
        
        # æ£€æŸ¥æ¿€å…‰åŠŸç‡
        if not (self.ranges['laserpower']['min'] <= laserpower <= self.ranges['laserpower']['max']):
            warnings_list.append(f"âš ï¸  æ¿€å…‰åŠŸç‡ {laserpower} è¶…å‡ºèŒƒå›´ [{self.ranges['laserpower']['min']}, {self.ranges['laserpower']['max']}]")
            severity = 'high'
        elif not (self.ranges['laserpower']['rec_min'] <= laserpower <= self.ranges['laserpower']['rec_max']):
            warnings_list.append(f"â„¹ï¸  æ¿€å…‰åŠŸç‡ {laserpower} åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼Œä½†å»ºè®®ä½¿ç”¨ [{self.ranges['laserpower']['rec_min']}, {self.ranges['laserpower']['rec_max']}]")
            if severity == 'none':
                severity = 'low'
        
        # æ£€æŸ¥æ€§åˆ«
        if gender not in [1, 2]:
            warnings_list.append(f"âš ï¸  æ€§åˆ«å€¼ {gender} æ— æ•ˆ (åº”ä¸º 1=ç”· æˆ– 2=å¥³)")
            severity = 'high'
        
        # æ£€æŸ¥å¹´é¾„
        if not (self.ranges['age']['min'] <= age <= self.ranges['age']['max']):
            warnings_list.append(f"âš ï¸  å¹´é¾„ {age} è¶…å‡ºè®­ç»ƒèŒƒå›´ [{self.ranges['age']['min']}, {self.ranges['age']['max']}]")
            severity = 'high'
        elif not (self.ranges['age']['rec_min'] <= age <= self.ranges['age']['rec_max']):
            warnings_list.append(f"âš ï¸  å¹´é¾„ {age} è¶…å‡ºå»ºè®®èŒƒå›´ [{self.ranges['age']['rec_min']}, {self.ranges['age']['rec_max']}]")
            warnings_list.append(f"   è®­ç»ƒæ•°æ®ä¸»è¦é›†ä¸­åœ¨21å²ï¼Œ25å²ä»¥ä¸Šæ ·æœ¬è¾ƒå°‘")
            if severity == 'none':
                severity = 'medium'
        
        # æ£€æŸ¥èº«é«˜
        if not (self.ranges['height']['min'] <= height <= self.ranges['height']['max']):
            warnings_list.append(f"âš ï¸  èº«é«˜ {height}cm è¶…å‡ºèŒƒå›´ [{self.ranges['height']['min']}, {self.ranges['height']['max']}]")
            if severity == 'none':
                severity = 'low'
        
        return warnings_list, severity
    
    def standardize_input(self, X, feature_name):
        """
        æ ‡å‡†åŒ–è¾“å…¥ï¼ˆä½¿ç”¨ç‰¹å¾ä¸“å±çš„inscalerï¼‰
        
        å‚æ•°:
            X: åŸå§‹è¾“å…¥ [laserpower, gender, age, height]
            feature_name: ç‰¹å¾åç§°
        
        è¿”å›:
            X_std: æ ‡å‡†åŒ–åçš„è¾“å…¥
        """
        X = np.atleast_1d(X)
        inscaler = self.inscalers[feature_name]
        
        return (X - inscaler['mean']) / inscaler['std']
    
    def _expand_covariates(self, X_std, params):
        """
        å±•å¼€åå˜é‡ï¼ˆåº”ç”¨B-splineå˜æ¢ï¼‰
        
        å‚æ•°:
            X_std: æ ‡å‡†åŒ–åçš„åå˜é‡ [laserpower_std, gender_std, age_std, height_std]
            params: ç‰¹å¾çš„æ¨¡å‹å‚æ•°
        
        è¿”å›:
            X_expanded: å±•å¼€åçš„åå˜é‡ï¼ˆåŒ…å«æˆªè·é¡¹ï¼‰
            
        æ³¨æ„ï¼š
            - slope_mu/slope_sigma çš„ç»´åº¦æ˜¯ (n_expanded_covariates,)
            - n_expanded_covariates = 1(æˆªè·) + n_bspline_bases + n_other_covariates
            - ä¾‹å¦‚: 1 + 7(B-spline bases for laserpower) + 3(gender, age, height) = 11
        """
        mu_basis_config = params.get('mu_basis', {})
        basis_column = mu_basis_config.get('basis_column', [])
        
        # æ£€æŸ¥æ˜¯å¦å¯¹ç¬¬ä¸€ä¸ªåå˜é‡ï¼ˆlaserpowerï¼‰åº”ç”¨B-spline
        if 0 in basis_column:
            laserpower_std = X_std[0]
            
            # è·å–B-splineèŠ‚ç‚¹
            knots_dict = mu_basis_config.get('knots', {})
            if '0' in knots_dict:
                knots = np.array(knots_dict['0'])
            else:
                # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰çš„èŠ‚ç‚¹ï¼Œç”Ÿæˆé»˜è®¤èŠ‚ç‚¹
                nknots = mu_basis_config.get('nknots', 5)
                degree = mu_basis_config.get('degree', 3)
                interior_knots = np.linspace(-2, 2, nknots)
                knots = np.concatenate([
                    np.repeat(interior_knots[0], degree),
                    interior_knots,
                    np.repeat(interior_knots[-1], degree)
                ])
            
            # åˆ›å»ºB-splineåŸºå‡½æ•°
            degree = mu_basis_config.get('degree', 3)
            bspline_bases = create_bspline_basis(laserpower_std, knots, degree)
            
            # å±•å¼€: [1(æˆªè·), B-spline_bases(7ä¸ª), gender, age, height]
            X_expanded = np.concatenate([
                [1.0],  # æˆªè·é¡¹
                bspline_bases,  # B-splineåŸºå‡½æ•°å€¼
                X_std[1:]  # å…¶ä»–åå˜é‡ (gender, age, height)
            ])
        else:
            # ä¸ä½¿ç”¨B-splineï¼Œç›´æ¥æ·»åŠ æˆªè·
            X_expanded = np.concatenate([[1.0], X_std])
        
        return X_expanded
    
    def predict_feature(self, feature_name, X_raw):
        """
        é¢„æµ‹å•ä¸ªç‰¹å¾
        
        å‚æ•°:
            feature_name: ç‰¹å¾åç§°
            X_raw: åŸå§‹åå˜é‡ [laserpower, gender, age, height]
        
        è¿”å›:
            ç»“æœå­—å…¸ï¼ŒåŒ…å« mean, std, lower_95, upper_95, z_score
        """
        params = self.model_params[feature_name]
        
        # 1. æ ‡å‡†åŒ–è¾“å…¥ï¼ˆä½¿ç”¨è¯¥ç‰¹å¾çš„inscalerï¼‰
        X_std = self.standardize_input(X_raw, feature_name)
        
        # 2. å±•å¼€åå˜é‡ï¼ˆåº”ç”¨B-splineï¼‰
        X_expanded = self._expand_covariates(X_std, params)
        
        # 3. ä»posteriorä¸­è·å–å‚æ•°
        posterior = params['posterior']
        
        # è·å–slope_muï¼ˆå›ºå®šæ•ˆåº”ç³»æ•°ï¼‰
        slope_mu = np.array(posterior['slope_mu']['mean'])
        
        # è·å–muçš„å±‚çº§æˆªè·
        mu_intercept_mu = posterior.get('mu_intercept_mu', {}).get('mean', 0.0)
        
        # 4. é¢„æµ‹ mu (æœŸæœ›å€¼)
        # mu = X_expanded @ slope_mu + mu_intercept_mu
        mu_pred_std = np.dot(X_expanded, slope_mu) + mu_intercept_mu
        
        # 5. é¢„æµ‹ sigma (æ ‡å‡†å·®)
        slope_sigma = np.array(posterior['slope_sigma']['mean'])
        intercept_sigma = posterior['intercept_sigma']['mean']
        
        # sigmaçš„çº¿æ€§é¢„æµ‹
        sigma_pred_linear = np.dot(X_expanded, slope_sigma) + intercept_sigma
        
        # åº”ç”¨softplusæ˜ å°„
        sigma_mapping_params = params['sigma_mapping']['params']
        sigma_pred_std = softplus(sigma_pred_linear, sigma_mapping_params)
        
        # 6. åæ ‡å‡†åŒ–åˆ°åŸå§‹å°ºåº¦
        outscaler = params['outscaler']
        mu_pred = mu_pred_std * outscaler['std'] + outscaler['mean']
        sigma_pred = sigma_pred_std * outscaler['std']
        
        # 7. è®¡ç®—ç½®ä¿¡åŒºé—´å’ŒZåˆ†æ•°
        lower_95 = mu_pred - 1.96 * sigma_pred
        upper_95 = mu_pred + 1.96 * sigma_pred
        
        # æ³¨æ„ï¼šZåˆ†æ•°éœ€è¦è§‚æµ‹å€¼ï¼Œè¿™é‡Œè¿”å›çš„æ˜¯é¢„æµ‹åˆ†å¸ƒçš„å‚æ•°
        # å®é™…Zåˆ†æ•°è®¡ç®—: z = (observed - mu_pred) / sigma_pred
        
        return {
            'mean': float(mu_pred),
            'std': float(sigma_pred),
            'lower_95': float(lower_95),
            'upper_95': float(upper_95),
            'mu_std': float(mu_pred_std),  # æ ‡å‡†åŒ–å°ºåº¦çš„muï¼ˆè°ƒè¯•ç”¨ï¼‰
            'sigma_std': float(sigma_pred_std)  # æ ‡å‡†åŒ–å°ºåº¦çš„sigmaï¼ˆè°ƒè¯•ç”¨ï¼‰
        }
    
    def calculate_z_score(self, feature_name, observed_value, predicted_result):
        """
        è®¡ç®—è§‚æµ‹å€¼çš„Zåˆ†æ•°
        
        å‚æ•°:
            feature_name: ç‰¹å¾åç§°
            observed_value: è§‚æµ‹å€¼
            predicted_result: predict_featureçš„è¿”å›ç»“æœ
        
        è¿”å›:
            z_score: Zåˆ†æ•°
        """
        z_score = (observed_value - predicted_result['mean']) / predicted_result['std']
        return float(z_score)
    
    def predict(self, laserpower, gender, age, height, show_warnings=True):
        """
        å®Œæ•´é¢„æµ‹æ‰€æœ‰ç‰¹å¾
        
        å‚æ•°:
            laserpower: æ¿€å…‰åŠŸç‡
            gender: æ€§åˆ« (1=ç”·, 2=å¥³)
            age: å¹´é¾„
            height: èº«é«˜ (cm)
            show_warnings: æ˜¯å¦æ˜¾ç¤ºè¾“å…¥æœ‰æ•ˆæ€§è­¦å‘Š
        
        è¿”å›:
            results: å­—å…¸ï¼Œé”®ä¸ºç‰¹å¾åï¼Œå€¼ä¸ºé¢„æµ‹ç»“æœ
        """
        # 1. æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        warnings_list, severity = self.check_input(laserpower, gender, age, height)
        
        # 2. æ˜¾ç¤ºè­¦å‘Š
        if show_warnings and warnings_list:
            print("\n" + "="*70)
            print("âš ï¸  è¾“å…¥æœ‰æ•ˆæ€§æ£€æŸ¥")
            print("="*70)
            for w in warnings_list:
                print(w)
            
            if severity == 'high':
                print("\nğŸ”´ ä¸¥é‡è­¦å‘Š: è¾“å…¥æ˜¾è‘—è¶…å‡ºè®­ç»ƒèŒƒå›´ï¼Œé¢„æµ‹å¯èƒ½ä¸å¯é ï¼")
            elif severity == 'medium':
                print("\nğŸŸ¡ è­¦å‘Š: è¾“å…¥æ¥è¿‘è®­ç»ƒèŒƒå›´è¾¹ç¼˜ï¼Œé¢„æµ‹ä¸ç¡®å®šæ€§è¾ƒé«˜")
            elif severity == 'low':
                print("\nğŸŸ¢ æç¤º: è¾“å…¥ç•¥å¾®åç¦»å»ºè®®èŒƒå›´")
            
            print("="*70)
            
            if severity == 'high':
                response = input("\næ˜¯å¦ç»§ç»­é¢„æµ‹ï¼Ÿ(y/n): ").strip().lower()
                if response != 'y':
                    print("âŒ å·²å–æ¶ˆé¢„æµ‹")
                    return None
            print()
        
        # 3. å‡†å¤‡è¾“å…¥
        X_raw = np.array([laserpower, gender, age, height])
        
        # 4. é¢„æµ‹æ‰€æœ‰ç‰¹å¾
        results = {}
        for feature in self.feature_names:
            try:
                results[feature] = self.predict_feature(feature, X_raw)
            except Exception as e:
                print(f"âš ï¸  é¢„æµ‹ç‰¹å¾ {feature} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                results[feature] = {
                    'mean': np.nan,
                    'std': np.nan,
                    'lower_95': np.nan,
                    'upper_95': np.nan
                }
        
        return results
    
    def predict_with_observations(self, laserpower, gender, age, height, observations):
        """
        é¢„æµ‹å¹¶è®¡ç®—Zåˆ†æ•°
        
        å‚æ•°:
            laserpower, gender, age, height: åå˜é‡
            observations: å­—å…¸ï¼Œé”®ä¸ºç‰¹å¾åï¼Œå€¼ä¸ºè§‚æµ‹å€¼
        
        è¿”å›:
            results: åŒ…å«é¢„æµ‹å€¼å’ŒZåˆ†æ•°çš„å­—å…¸
        """
        # è·å–é¢„æµ‹ç»“æœ
        predictions = self.predict(laserpower, gender, age, height, show_warnings=False)
        
        if predictions is None:
            return None
        
        # è®¡ç®—Zåˆ†æ•°
        for feature, pred in predictions.items():
            if feature in observations and not np.isnan(observations[feature]):
                z_score = self.calculate_z_score(feature, observations[feature], pred)
                pred['observed'] = observations[feature]
                pred['z_score'] = z_score
            else:
                pred['observed'] = np.nan
                pred['z_score'] = np.nan
        
        return predictions


def print_results(results, laserpower, gender, age, height, show_debug=False):
    """
    æ‰“å°é¢„æµ‹ç»“æœ
    
    å‚æ•°:
        results: é¢„æµ‹ç»“æœå­—å…¸
        laserpower, gender, age, height: è¾“å…¥åå˜é‡
        show_debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆæ ‡å‡†åŒ–å°ºåº¦çš„å€¼ï¼‰
    """
    if results is None:
        return
    
    print("\n" + "="*70)
    print("ğŸ“Š é¢„æµ‹ç»“æœ")
    print("="*70)
    print(f"\nè¾“å…¥å‚æ•°:")
    print(f"  æ¿€å…‰åŠŸç‡: {laserpower}")
    print(f"  æ€§åˆ«:     {gender} ({'ç”·' if gender == 1 else 'å¥³'})")
    print(f"  å¹´é¾„:     {age} å²")
    print(f"  èº«é«˜:     {height} cm")
    
    print(f"\né¢„æµ‹å€¼ (å‡å€¼ Â± æ ‡å‡†å·®):")
    print("-"*70)
    
    for feature, pred in results.items():
        mean = pred['mean']
        std = pred['std']
        lower = pred['lower_95']
        upper = pred['upper_95']
        
        # åŸºæœ¬ä¿¡æ¯
        info_str = f"{feature:12s}: {mean:8.2f} Â± {std:6.2f}  (95% CI: [{lower:7.2f}, {upper:7.2f}])"
        
        # å¦‚æœæœ‰è§‚æµ‹å€¼å’ŒZåˆ†æ•°
        if 'observed' in pred and not np.isnan(pred['observed']):
            obs = pred['observed']
            z = pred['z_score']
            info_str += f"  | Obs: {obs:7.2f}, Z: {z:6.2f}"
        
        print(info_str)
    
    if show_debug:
        print("\nè°ƒè¯•ä¿¡æ¯ (æ ‡å‡†åŒ–å°ºåº¦):")
        print("-"*70)
        for feature, pred in results.items():
            if 'mu_std' in pred and 'sigma_std' in pred:
                print(f"{feature:12s}: Î¼_std={pred['mu_std']:7.4f}, Ïƒ_std={pred['sigma_std']:7.4f}")
    
    print("="*70)


def interactive_mode(predictor):
    """äº¤äº’å¼è¾“å…¥æ¨¡å¼"""
    print("\n" + "="*70)
    print("ğŸ¯ äº¤äº’å¼é¢„æµ‹æ¨¡å¼")
    print("="*70)
    print("\nåå˜é‡è¾“å…¥è¯´æ˜:")
    print("  â€¢ æ¿€å…‰åŠŸç‡: 1.0-4.5 (å»ºè®® 2.5-4.0)")
    print("  â€¢ æ€§åˆ«:     1=ç”·, 2=å¥³")
    print("  â€¢ å¹´é¾„:     å»ºè®® 18-25å² (è®­ç»ƒèŒƒå›´ 16-50)")
    print("  â€¢ èº«é«˜:     150-190 cm")
    print("\nå‘½ä»¤:")
    print("  â€¢ è¾“å…¥ 'q' é€€å‡º")
    print("  â€¢ è¾“å…¥ 'b' è¿›å…¥æ‰¹é‡é¢„æµ‹æ¨¡å¼")
    print("  â€¢ è¾“å…¥ 'z' è¿›å…¥å¸¦è§‚æµ‹å€¼çš„é¢„æµ‹æ¨¡å¼ï¼ˆè®¡ç®—Zåˆ†æ•°ï¼‰")
    print()
    
    while True:
        try:
            print("-"*70)
            power_input = input("æ¿€å…‰åŠŸç‡ (q=é€€å‡º, b=æ‰¹é‡, z=Zåˆ†æ•°æ¨¡å¼): ").strip()
            
            if power_input.lower() == 'q':
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            if power_input.lower() == 'b':
                print("\nåˆ‡æ¢åˆ°æ‰¹é‡é¢„æµ‹æ¨¡å¼...")
                input_file = input("è¾“å…¥æ–‡ä»¶è·¯å¾„: ").strip()
                output_file = input("è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: predictions.csv): ").strip()
                if not output_file:
                    output_file = 'predictions.csv'
                batch_mode(predictor, input_file, output_file)
                print("\nè¿”å›äº¤äº’å¼æ¨¡å¼")
                continue
            
            if power_input.lower() == 'z':
                print("\nåˆ‡æ¢åˆ°å¸¦è§‚æµ‹å€¼çš„é¢„æµ‹æ¨¡å¼...")
                z_score_mode(predictor)
                print("\nè¿”å›äº¤äº’å¼æ¨¡å¼")
                continue
            
            # è·å–è¾“å…¥
            laserpower = float(power_input)
            gender = int(input("æ€§åˆ« (1=ç”·, 2=å¥³): "))
            age = float(input("å¹´é¾„: "))
            height = float(input("èº«é«˜ (cm): "))
            
            # é¢„æµ‹
            results = predictor.predict(laserpower, gender, age, height)
            print_results(results, laserpower, gender, age, height)
            
        except ValueError as e:
            print(f"\nâŒ è¾“å…¥é”™è¯¯: {e}")
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


def z_score_mode(predictor):
    """å¸¦è§‚æµ‹å€¼çš„é¢„æµ‹æ¨¡å¼ï¼ˆè®¡ç®—Zåˆ†æ•°ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ“ˆ Zåˆ†æ•°è®¡ç®—æ¨¡å¼")
    print("="*70)
    print("\nåœ¨æ­¤æ¨¡å¼ä¸‹ï¼Œæ‚¨å¯ä»¥è¾“å…¥è§‚æµ‹å€¼æ¥è®¡ç®—Zåˆ†æ•°")
    print("Zåˆ†æ•°è¡¨ç¤ºè§‚æµ‹å€¼åç¦»é¢„æµ‹å‡å€¼çš„æ ‡å‡†å·®æ•°")
    print()
    
    try:
        # è·å–åå˜é‡
        laserpower = float(input("æ¿€å…‰åŠŸç‡: "))
        gender = int(input("æ€§åˆ« (1=ç”·, 2=å¥³): "))
        age = float(input("å¹´é¾„: "))
        height = float(input("èº«é«˜ (cm): "))
        
        # è·å–è§‚æµ‹å€¼
        print("\nè¯·è¾“å…¥è§‚æµ‹å€¼ï¼ˆç•™ç©ºè·³è¿‡è¯¥ç‰¹å¾ï¼‰:")
        observations = {}
        for feature in predictor.feature_names:
            obs_input = input(f"  {feature}: ").strip()
            if obs_input:
                try:
                    observations[feature] = float(obs_input)
                except ValueError:
                    print(f"    âš ï¸  æ— æ•ˆè¾“å…¥ï¼Œè·³è¿‡ {feature}")
        
        # é¢„æµ‹å¹¶è®¡ç®—Zåˆ†æ•°
        results = predictor.predict_with_observations(
            laserpower, gender, age, height, observations
        )
        
        # æ˜¾ç¤ºç»“æœ
        print_results(results, laserpower, gender, age, height)
        
        # è§£é‡ŠZåˆ†æ•°
        print("\nZåˆ†æ•°è§£é‡Š:")
        print("  |Z| < 1.96: åœ¨95%ç½®ä¿¡åŒºé—´å†…ï¼ˆæ­£å¸¸ï¼‰")
        print("  |Z| > 1.96: è¶…å‡º95%ç½®ä¿¡åŒºé—´ï¼ˆå¼‚å¸¸ï¼‰")
        print("  |Z| > 2.58: è¶…å‡º99%ç½®ä¿¡åŒºé—´ï¼ˆé«˜åº¦å¼‚å¸¸ï¼‰")
        
    except ValueError as e:
        print(f"\nâŒ è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def batch_mode(predictor, input_file, output_file):
    """
    æ‰¹é‡é¢„æµ‹æ¨¡å¼
    
    è¾“å…¥CSVæ ¼å¼ï¼šè‡³å°‘åŒ…å«åˆ— laserpower, gender, age, height
    å¯é€‰åˆ—ï¼šå„ç‰¹å¾çš„è§‚æµ‹å€¼ï¼ˆç”¨äºè®¡ç®—Zåˆ†æ•°ï¼‰
    """
    print("\n" + "="*70)
    print("ğŸ“ æ‰¹é‡é¢„æµ‹æ¨¡å¼")
    print("="*70)
    
    try:
        df = pd.read_csv(input_file)
    except Exception as e:
        print(f"\nâŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥å¿…éœ€åˆ—
    required_cols = ['laserpower', 'gender', 'age', 'height']
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing}")
        return
    
    print(f"\nâœ“ æ‰¾åˆ° {len(df)} ä¸ªæ ·æœ¬")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è§‚æµ‹å€¼åˆ—
    has_observations = any(f in df.columns for f in predictor.feature_names)
    if has_observations:
        print("âœ“ æ£€æµ‹åˆ°è§‚æµ‹å€¼åˆ—ï¼Œå°†è®¡ç®—Zåˆ†æ•°")
    
    print("å¼€å§‹é¢„æµ‹...\n")
    
    all_results = []
    warnings_count = 0
    
    for idx, row in df.iterrows():
        # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        warnings_list, severity = predictor.check_input(
            row['laserpower'], row['gender'], row['age'], row['height']
        )
        
        if warnings_list:
            warnings_count += 1
        
        # å‡†å¤‡è§‚æµ‹å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
        observations = {}
        if has_observations:
            for feature in predictor.feature_names:
                if feature in df.columns and not pd.isna(row[feature]):
                    observations[feature] = row[feature]
        
        # é¢„æµ‹
        if observations:
            results = predictor.predict_with_observations(
                row['laserpower'], row['gender'], row['age'], row['height'],
                observations
            )
        else:
            results = predictor.predict(
                row['laserpower'], row['gender'], row['age'], row['height'],
                show_warnings=False
            )
        
        if results:
            # æ„å»ºè¾“å‡ºè¡Œ
            flat_result = {
                'index': idx,
                'laserpower': row['laserpower'],
                'gender': row['gender'],
                'age': row['age'],
                'height': row['height'],
                'has_warnings': len(warnings_list) > 0,
                'warning_severity': severity
            }
            
            # æ·»åŠ é¢„æµ‹ç»“æœ
            for feature, pred in results.items():
                flat_result[f'{feature}_pred_mean'] = pred['mean']
                flat_result[f'{feature}_pred_std'] = pred['std']
                flat_result[f'{feature}_pred_lower95'] = pred['lower_95']
                flat_result[f'{feature}_pred_upper95'] = pred['upper_95']
                
                # å¦‚æœæœ‰è§‚æµ‹å€¼å’ŒZåˆ†æ•°
                if 'observed' in pred:
                    flat_result[f'{feature}_observed'] = pred['observed']
                if 'z_score' in pred:
                    flat_result[f'{feature}_z_score'] = pred['z_score']
            
            all_results.append(flat_result)
        
        # æ˜¾ç¤ºè¿›åº¦
        if (idx + 1) % 10 == 0:
            print(f"  å·²å¤„ç† {idx + 1}/{len(df)} ä¸ªæ ·æœ¬...")
    
    # ä¿å­˜ç»“æœ
    results_df = pd.DataFrame(all_results)
    results_df.to_csv(output_file, index=False)
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼")
    print(f"  ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"  æ€»æ ·æœ¬æ•°: {len(results_df)}")
    print(f"  æœ‰è­¦å‘Šçš„æ ·æœ¬: {warnings_count}")
    
    # ç»Ÿè®¡å¼‚å¸¸Zåˆ†æ•°ï¼ˆå¦‚æœè®¡ç®—äº†Zåˆ†æ•°ï¼‰
    if has_observations:
        z_cols = [col for col in results_df.columns if col.endswith('_z_score')]
        if z_cols:
            print(f"\nZåˆ†æ•°ç»Ÿè®¡:")
            for z_col in z_cols:
                feature = z_col.replace('_z_score', '')
                z_values = results_df[z_col].dropna()
                if len(z_values) > 0:
                    n_abnormal = (z_values.abs() > 1.96).sum()
                    print(f"  {feature}: {n_abnormal}/{len(z_values)} æ ·æœ¬å¼‚å¸¸ (|Z| > 1.96)")


def quick_mode(predictor, laserpower, gender, age, height):
    """å¿«é€Ÿé¢„æµ‹æ¨¡å¼ï¼ˆå‘½ä»¤è¡Œï¼‰"""
    results = predictor.predict(laserpower, gender, age, height)
    print_results(results, laserpower, gender, age, height)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="HBRäº¤äº’å¼é¢„æµ‹å™¨ - æŒ‰ç‰¹å¾åˆ†åˆ«è®­ç»ƒç‰ˆæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. äº¤äº’å¼æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰:
   python predictor_by_feature.py

2. å¿«é€Ÿé¢„æµ‹:
   python predictor_by_feature.py -q 3.5 1 21 170

3. æ‰¹é‡é¢„æµ‹:
   python predictor_by_feature.py -b input.csv -o output.csv

4. æŒ‡å®šå‚æ•°æ–‡ä»¶:
   python predictor_by_feature.py -p extracted_model_params.json

åå˜é‡è¯´æ˜:
  â€¢ laserpower: æ¿€å…‰åŠŸç‡ (1.0-4.5, å»ºè®®2.5-4.0)
  â€¢ gender: æ€§åˆ« (1=ç”·, 2=å¥³)
  â€¢ age: å¹´é¾„ (å»ºè®®18-25å²)
  â€¢ height: èº«é«˜ (150-190 cm)
        """
    )
    
    parser.add_argument('-p', '--params', help='å‚æ•°æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-q', '--quick', nargs=4, 
                       metavar=('POWER', 'GENDER', 'AGE', 'HEIGHT'),
                       help='å¿«é€Ÿé¢„æµ‹æ¨¡å¼')
    parser.add_argument('-b', '--batch', metavar='INPUT', help='æ‰¹é‡é¢„æµ‹è¾“å…¥æ–‡ä»¶')
    parser.add_argument('-o', '--output', metavar='OUTPUT', help='æ‰¹é‡é¢„æµ‹è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('-d', '--debug', action='store_true', help='æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("\n" + "="*70)
    print("ğŸš€ HBRäº¤äº’å¼é¢„æµ‹å™¨ - æŒ‰ç‰¹å¾åˆ†åˆ«è®­ç»ƒç‰ˆæœ¬")
    print("="*70)
    
    # åŠ è½½é¢„æµ‹å™¨
    try:
        predictor = HBRPredictorByFeature(args.params)
        print(f"\nâœ“ ä½¿ç”¨å‚æ•°æ–‡ä»¶: {predictor.params_file}")
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(predictor.feature_names)} ä¸ªç‰¹å¾æ¨¡å‹:")
        for i, feature in enumerate(predictor.feature_names, 1):
            print(f"   {i}. {feature}")
    except Exception as e:
        print(f"\nâŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.quick:
        try:
            laserpower = float(args.quick[0])
            gender = int(args.quick[1])
            age = float(args.quick[2])
            height = float(args.quick[3])
            quick_mode(predictor, laserpower, gender, age, height)
        except ValueError as e:
            print(f"\nâŒ å‚æ•°é”™è¯¯: {e}")
            sys.exit(1)
    
    elif args.batch:
        if not args.output:
            print("âŒ æ‰¹é‡æ¨¡å¼éœ€è¦æŒ‡å®šè¾“å‡ºæ–‡ä»¶ (-o)")
            sys.exit(1)
        batch_mode(predictor, args.batch, args.output)
    
    else:
        interactive_mode(predictor)


if __name__ == "__main__":
    main()
